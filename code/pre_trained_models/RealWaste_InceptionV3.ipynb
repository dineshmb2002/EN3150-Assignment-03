{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5f51f9d",
   "metadata": {},
   "source": [
    "\n",
    "# RealWaste — Inception V3 (Using Manifest + Numpy Splits)\n",
    "\n",
    "This notebook loads the dataset **from your manifest-driven splits** saved as `.npy` files:\n",
    "- `filepaths.npy`, `labels_encoded.npy`, `class_names.npy`\n",
    "- `split_train.npy`, `split_val.npy`, `split_test.npy`\n",
    "- `mean_std.npy` (optional: dataset mean/std you computed)\n",
    "\n",
    "It fine-tunes **Inception V3** and reports **Accuracy, macro Precision/Recall/F1** and a **confusion matrix**.\n",
    "\n",
    "> **Prereq:** Run your `02_Splits_MeanStd_AugPreview.ipynb` first to generate the npy files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acd3c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (Optional) Install dependencies if needed\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "# !pip install scikit-learn matplotlib pandas tqdm pillow numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7b4686",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# === Paths to your NPZ/NPY assets ===\n",
    "SPLITS_DIR = Path(\"./\")  # change if your npy files are elsewhere\n",
    "\n",
    "FILEPATHS_NPY = SPLITS_DIR / \"filepaths.npy\"\n",
    "LABELS_NPY    = SPLITS_DIR / \"labels_encoded.npy\"\n",
    "CLASSES_NPY   = SPLITS_DIR / \"class_names.npy\"\n",
    "TRAIN_NPY     = SPLITS_DIR / \"split_train.npy\"\n",
    "VAL_NPY       = SPLITS_DIR / \"split_val.npy\"\n",
    "TEST_NPY      = SPLITS_DIR / \"split_test.npy\"\n",
    "MEAN_STD_NPY  = SPLITS_DIR / \"mean_std.npy\"   # optional\n",
    "\n",
    "# === Training config ===\n",
    "OUTPUT_DIR = Path(\"./outputs/inception_v3_realwaste_splits\").resolve()\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SEED = 133\n",
    "BATCH_SIZE = 32\n",
    "HEAD_EPOCHS = 5\n",
    "FT_EPOCHS = 25\n",
    "BASE_LR = 3e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "LABEL_SMOOTH = 0.1\n",
    "IMG_SIZE = 299  # Inception V3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89931d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random, os, numpy as np, torch\n",
    "\n",
    "def set_seed(seed=133):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(SEED)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f16df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load arrays\n",
    "filepaths = np.load(FILEPATHS_NPY, allow_pickle=True)\n",
    "labels    = np.load(LABELS_NPY)\n",
    "classes   = np.load(CLASSES_NPY, allow_pickle=True).tolist()\n",
    "idx_tr    = np.load(TRAIN_NPY)\n",
    "idx_va    = np.load(VAL_NPY)\n",
    "idx_te    = np.load(TEST_NPY)\n",
    "\n",
    "# Mean/std if you computed them; else fall back to ImageNet stats\n",
    "try:\n",
    "    mean_std = np.load(MEAN_STD_NPY)\n",
    "    mean = mean_std[0].tolist()\n",
    "    std  = mean_std[1].tolist()\n",
    "    print(\"Using dataset mean/std:\", mean, std)\n",
    "except Exception as e:\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std  = [0.229, 0.224, 0.225]\n",
    "    print(\"No mean_std.npy found; using ImageNet stats.\")\n",
    "    \n",
    "len(classes), classes[:5], len(idx_tr), len(idx_va), len(idx_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac78ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class NpySplitDataset(Dataset):\n",
    "    def __init__(self, filepaths, labels, indices, img_size=299, train=True, mean=None, std=None):\n",
    "        self.filepaths = filepaths\n",
    "        self.labels = labels\n",
    "        self.indices = indices\n",
    "        self.train = train\n",
    "        self.mean = mean or [0.485,0.456,0.406]\n",
    "        self.std  = std  or [0.229,0.224,0.225]\n",
    "        if train:\n",
    "            self.tf = transforms.Compose([\n",
    "                transforms.Resize(int(img_size*1.15)),\n",
    "                transforms.CenterCrop(img_size),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.ColorJitter(0.1,0.1,0.1,0.05),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(self.mean, self.std),\n",
    "            ])\n",
    "        else:\n",
    "            self.tf = transforms.Compose([\n",
    "                transforms.Resize(int(img_size*1.15)),\n",
    "                transforms.CenterCrop(img_size),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(self.mean, self.std),\n",
    "            ])\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    def __getitem__(self, i):\n",
    "        idx = int(self.indices[i])\n",
    "        fp = str(self.filepaths[idx])\n",
    "        y  = int(self.labels[idx])\n",
    "        img = Image.open(fp).convert(\"RGB\")\n",
    "        x = self.tf(img)\n",
    "        return x, y\n",
    "\n",
    "train_ds = NpySplitDataset(filepaths, labels, idx_tr, img_size=IMG_SIZE, train=True,  mean=mean, std=std)\n",
    "val_ds   = NpySplitDataset(filepaths, labels, idx_va, img_size=IMG_SIZE, train=False, mean=mean, std=std)\n",
    "test_ds  = NpySplitDataset(filepaths, labels, idx_te, img_size=IMG_SIZE, train=False, mean=mean, std=std)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "val_dl   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_dl  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "len(train_ds), len(val_ds), len(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d510e31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "def make_inception_v3(num_classes: int, aux_logits=True):\n",
    "    m = models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1, aux_logits=aux_logits)\n",
    "    m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
    "    if aux_logits and hasattr(m, \"AuxLogits\") and m.AuxLogits:\n",
    "        m.AuxLogits.fc = nn.Linear(m.AuxLogits.fc.in_features, num_classes)\n",
    "    return m\n",
    "\n",
    "model = make_inception_v3(num_classes=len(classes), aux_logits=True).to(device)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23536e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch, torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_one_epoch(model, dl, optimizer, device, use_aux=True, smoothing=0.1):\n",
    "    model.train()\n",
    "    total, correct, loss_sum = 0, 0, 0.0\n",
    "    for x, y in tqdm(dl, leave=False):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        if use_aux and isinstance(out, tuple):  # (main, aux)\n",
    "            out_main, out_aux = out\n",
    "            loss = F.cross_entropy(out_main, y, label_smoothing=smoothing) +                    0.4 * F.cross_entropy(out_aux, y, label_smoothing=smoothing)\n",
    "            pred = out_main.argmax(1)\n",
    "        else:\n",
    "            loss = F.cross_entropy(out, y, label_smoothing=smoothing)\n",
    "            pred = out.argmax(1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        bs = y.size(0)\n",
    "        loss_sum += loss.item() * bs\n",
    "        correct  += (pred == y).sum().item()\n",
    "        total    += bs\n",
    "\n",
    "    return loss_sum/total, correct/total\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dl, device, use_aux=True):\n",
    "    model.eval()\n",
    "    total, correct, loss_sum = 0, 0, 0.0\n",
    "    for x, y in dl:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        out = model(x)\n",
    "        if use_aux and isinstance(out, tuple):\n",
    "            out = out[0]\n",
    "        loss = F.cross_entropy(out, y)\n",
    "        pred = out.argmax(1)\n",
    "\n",
    "        bs = y.size(0)\n",
    "        loss_sum += loss.item() * bs\n",
    "        correct  += (pred == y).sum().item()\n",
    "        total    += bs\n",
    "\n",
    "    return loss_sum/total, correct/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4572982d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Train classifier head only\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "if hasattr(model, \"fc\"):\n",
    "    for p in model.fc.parameters():\n",
    "        p.requires_grad = True\n",
    "if hasattr(model, \"AuxLogits\") and model.AuxLogits:\n",
    "    for p in model.AuxLogits.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "opt = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=BASE_LR, weight_decay=WEIGHT_DECAY)\n",
    "sch = CosineAnnealingLR(opt, T_max=HEAD_EPOCHS)\n",
    "\n",
    "use_aux = True\n",
    "best_val_acc = -1.0\n",
    "best_state = None\n",
    "\n",
    "for ep in range(1, HEAD_EPOCHS+1):\n",
    "    tr_loss, tr_acc = train_one_epoch(model, train_dl, opt, device, use_aux, LABEL_SMOOTH)\n",
    "    va_loss, va_acc = evaluate(model, val_dl, device, use_aux)\n",
    "    sch.step()\n",
    "    print(f\"[head][{ep:02d}/{HEAD_EPOCHS}] train_acc={tr_acc:.4f}  val_acc={va_acc:.4f}\")\n",
    "    if va_acc > best_val_acc:\n",
    "        best_val_acc = va_acc\n",
    "        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "\n",
    "# Save head-only best (optional)\n",
    "from pathlib import Path\n",
    "if best_state is not None:\n",
    "    head_ckpt = Path(OUTPUT_DIR) / \"inception_v3_head_best.pth\"\n",
    "    import torch\n",
    "    torch.save(best_state, head_ckpt)\n",
    "    print(\"Saved:\", head_ckpt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2bffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Fine-tune all layers\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "opt = AdamW(model.parameters(), lr=BASE_LR/3, weight_decay=WEIGHT_DECAY)\n",
    "sch = CosineAnnealingLR(opt, T_max=FT_EPOCHS)\n",
    "\n",
    "best_val_acc = -1.0\n",
    "best_state = None\n",
    "\n",
    "for ep in range(1, FT_EPOCHS+1):\n",
    "    tr_loss, tr_acc = train_one_epoch(model, train_dl, opt, device, use_aux, LABEL_SMOOTH)\n",
    "    va_loss, va_acc = evaluate(model, val_dl, device, use_aux)\n",
    "    sch.step()\n",
    "    print(f\"[ft  ][{ep:02d}/{FT_EPOCHS}] train_acc={tr_acc:.4f}  val_acc={va_acc:.4f}\")\n",
    "    if va_acc > best_val_acc:\n",
    "        best_val_acc = va_acc\n",
    "        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "\n",
    "best_ckpt = Path(OUTPUT_DIR) / \"inception_v3_best.pth\"\n",
    "if best_state is not None:\n",
    "    import torch\n",
    "    torch.save(best_state, best_ckpt)\n",
    "    print(\"Saved best fine-tuned checkpoint:\", best_ckpt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e6586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_all(model, dl, device, use_aux=True):\n",
    "    model.eval()\n",
    "    ys, ps = [], []\n",
    "    for x, y in dl:\n",
    "        x = x.to(device)\n",
    "        out = model(x)\n",
    "        if use_aux and isinstance(out, tuple):\n",
    "            out = out[0]\n",
    "        pred = out.argmax(1).cpu().numpy()\n",
    "        ys.append(y.numpy())\n",
    "        ps.append(pred)\n",
    "    y = np.concatenate(ys)\n",
    "    p = np.concatenate(ps)\n",
    "    return y, p\n",
    "\n",
    "# Load best weights\n",
    "state = torch.load(best_ckpt, map_location=\"cpu\")\n",
    "model.load_state_dict(state)\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_dl, device, use_aux=True)\n",
    "y_true, y_pred = predict_all(model, test_dl, device, use_aux=True)\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(\"Test Accuracy:\", acc)\n",
    "print(\"Macro Precision:\", prec)\n",
    "print(\"Macro Recall:\", rec)\n",
    "print(\"Macro F1:\", f1)\n",
    "\n",
    "# Save metrics to CSV\n",
    "df = pd.DataFrame([{\n",
    "    \"model\": \"inception_v3\",\n",
    "    \"accuracy\": acc,\n",
    "    \"precision_macro\": prec,\n",
    "    \"recall_macro\": rec,\n",
    "    \"f1_macro\": f1\n",
    "}])\n",
    "csv_path = Path(OUTPUT_DIR) / \"results.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "csv_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29936eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "plt.imshow(cm, interpolation='nearest')\n",
    "plt.title('Confusion Matrix — Inception V3 (npy splits)')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=90)\n",
    "plt.yticks(tick_marks, classes)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.tight_layout()\n",
    "\n",
    "cm_path = Path(OUTPUT_DIR) / \"confusion_matrix_inception_v3_splits.png\"\n",
    "plt.savefig(cm_path, dpi=150, bbox_inches=\"tight\")\n",
    "cm_path\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
